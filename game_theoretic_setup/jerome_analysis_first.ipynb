{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f5d9d8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8ffec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda237a",
   "metadata": {},
   "source": [
    "# General variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3f962",
   "metadata": {},
   "source": [
    " ## Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d883acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pattern of filenames\n",
    "\n",
    "GameTheoretic_filename_pattern_DQN =  re.compile(r\"results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_DQN_\"\n",
    "                                                r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "                                                r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[\\d.]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "                                                r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "                                                r\"(?P<batch_size>[\\d.]+)_(?P<hidden_size>[\\d.]+)_(?P<update_target_every>[\\d.]+)_\"\n",
    "                                                r\"(?P<random_suffix>\\d{6})_(?P<suffix>[^_]+)\\.csv\"\n",
    ")\n",
    "\n",
    "GameTheoretic_filename_pattern_QL = re.compile(r\"results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_QLearning_\"\n",
    "                                              r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "                                              r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[\\d.]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "                                              r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "                                              r\"(?P<random_suffix>\\d{6})_(?P<suffix>[^_]+)\\.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "Maze2D_filename_order_QL = re.compile(\n",
    "    r\"maze2d_results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_QLearning_\"\n",
    "    r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "    r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[\\d.]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "    r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "    r\"(?P<random_suffix>\\d{6})_(?P<suffix>[^_]+)\\.csv\"\n",
    ")\n",
    "\n",
    "Maze2D_filename_order_DQN = re.compile(\n",
    "    r\"maze2d_results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_DQN_\"\n",
    "    r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "    r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[\\d.]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "    r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "    r\"(?P<batch_size>[\\d.]+)_(?P<hidden_size>[\\d.]+)_(?P<update_target_every>[\\d.]+)_\"\n",
    "    r\"(?P<random_suffix>\\d{6})_(?P<suffix>[^_]+)\\.csv\"\n",
    ")\n",
    "\n",
    "FILENAME_PATTERNS = [\n",
    "    GameTheoretic_filename_pattern_DQN,\n",
    "    GameTheoretic_filename_pattern_QL,\n",
    "    Maze2D_filename_order_DQN,\n",
    "    Maze2D_filename_order_QL\n",
    "]\n",
    "\n",
    "FILENAME_PATTERNS_PAIR = [\n",
    "    (\"Gametheoretic\", GameTheoretic_filename_pattern_DQN),\n",
    "    (\"Gametheoretic\", GameTheoretic_filename_pattern_QL),\n",
    "    (\"maze2d\", Maze2D_filename_order_DQN),\n",
    "    (\"maze2d\", Maze2D_filename_order_QL)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810fa323",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4083a",
   "metadata": {},
   "source": [
    "## CSV processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad5067",
   "metadata": {},
   "source": [
    "### Parameter recovery from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2748031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results_filenames(folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scans a folder for result filenames and extracts simulation parameters into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing result CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing parsed parameters from filenames.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        for pattern in FILENAME_PATTERNS:\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                file_data = match.groupdict()\n",
    "                file_data[\"filename\"] = filename\n",
    "                data.append(file_data)\n",
    "                break  # Stop at the first match\n",
    "\n",
    "    if not data:\n",
    "        print(\"No matching filenames found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Optional: convert numeric fields from str to float/int\n",
    "    for col in df.columns:\n",
    "        if col not in {\"filename\", \"emotion\", \"see_emotions\", \"suffix\"}:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "            except:\n",
    "                pass  # leave as string if conversion fails\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffa3efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results_by_suffix(folder_path: str, target_suffix: str, source_filter: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates CSV files with a given suffix and optionally filters by source ('maze2d' or 'gametheoretic').\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Folder containing result files.\n",
    "        target_suffix (str): e.g. \"episode_summary\" or \"step_data\".\n",
    "        source_filter (str, optional): If set to \"maze2d\" or \"gametheoretic\", only those files will be included.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated DataFrame with data and filename metadata.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        for source_type, pattern in FILENAME_PATTERNS:\n",
    "            if source_filter and source_type != source_filter:\n",
    "                continue  # Skip if not matching the desired source\n",
    "\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                metadata = match.groupdict()\n",
    "                if metadata.get(\"suffix\") == target_suffix:\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        for key, value in metadata.items():\n",
    "                            df[key] = value\n",
    "                        df[\"source\"] = source_type\n",
    "                        all_data.append(df)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {filename}: {e}\")\n",
    "                break  # Stop at first matching pattern\n",
    "\n",
    "    if not all_data:\n",
    "        print(f\"No matching files found for suffix '{target_suffix}' and source '{source_filter}'.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Try numeric conversion for non-categorical columns\n",
    "    for col in final_df.columns:\n",
    "        if col not in {\"emotion\", \"see_emotions\", \"suffix\", \"filename\", \"source\"}:\n",
    "            try:\n",
    "                final_df[col] = pd.to_numeric(final_df[col])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Save output\n",
    "    filtered_tag = f\"_{source_filter}\" if source_filter else \"\"\n",
    "    output_filename = f\"aggregated_{target_suffix}{filtered_tag}.csv\"\n",
    "    output_path = os.path.join(folder_path, output_filename)\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved aggregated data to: {output_path}\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b353f5a",
   "metadata": {},
   "source": [
    "### Raw files to summary DataFrame and csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16bd09d",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b159a",
   "metadata": {},
   "source": [
    " ### Learning verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def windowed_avg_combined_reward(\n",
    "    df: pd.DataFrame,\n",
    "    reward_prefix: str = \"total_combined_reward_\",\n",
    "    episode_column: str = \"episode\",\n",
    "    simulation_id_column: str = \"simulation_index\",\n",
    "    window_size: int = 5,\n",
    "    aggregation_mode: str = \"mean\",  # or \"best\"\n",
    "    plot: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes a windowed moving average of combined rewards per episode across simulations.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        reward_prefix (str): Prefix of reward columns per agent.\n",
    "        episode_column (str): Column name for episodes.\n",
    "        simulation_id_column (str): Column indicating different simulations.\n",
    "        window_size (int): Window size for moving average.\n",
    "        aggregation_mode (str): 'mean' for average across agents, 'best' for max reward among agents.\n",
    "        plot (bool): Whether to plot the result.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with ['episode', 'aggregated_reward', 'moving_avg'].\n",
    "    \"\"\"\n",
    "    reward_cols = [col for col in df.columns if col.startswith(reward_prefix)]\n",
    "    if not reward_cols:\n",
    "        raise ValueError(f\"No columns found with prefix '{reward_prefix}'\")\n",
    "\n",
    "    if aggregation_mode == \"mean\":\n",
    "        df[\"aggregated_reward\"] = df[reward_cols].mean(axis=1)\n",
    "    elif aggregation_mode == \"best\":\n",
    "        df[\"aggregated_reward\"] = df[reward_cols].max(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"aggregation_mode must be 'mean' or 'best'\")\n",
    "\n",
    "    # Group by episode and average over simulations\n",
    "    episode_avg = (\n",
    "        df.groupby(episode_column)[\"aggregated_reward\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"aggregated_reward\": \"mean_reward\"})\n",
    "    )\n",
    "\n",
    "    # Apply moving average\n",
    "    episode_avg[\"moving_avg\"] = (\n",
    "        episode_avg[\"mean_reward\"].rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(episode_avg[episode_column], episode_avg[\"moving_avg\"], label=f\"Moving Avg ({aggregation_mode})\")\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.title(f\"{aggregation_mode.capitalize()} Agent Reward (Window={window_size})\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return episode_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96180ba",
   "metadata": {},
   "source": [
    "### Variable_calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db0720",
   "metadata": {},
   "source": [
    "#### Gini coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da6bcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coefficient(arr: np.ndarray) -> float:\n",
    "    \"\"\"Compute Gini coefficient of a 1D numpy array.\"\"\"\n",
    "    arr = arr.flatten()\n",
    "    if np.amin(arr) < 0:\n",
    "        arr = arr - np.amin(arr)  # Shift if negative values present\n",
    "    mean = np.mean(arr)\n",
    "    if mean == 0:\n",
    "        return 0.0\n",
    "    n = len(arr)\n",
    "    diff_sum = np.sum(np.abs(np.subtract.outer(arr, arr)))\n",
    "    gini = diff_sum / (2 * n**2 * mean)\n",
    "    return gini\n",
    "\n",
    "def compute_gini_for_df(df: pd.DataFrame, prefix: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute Gini coefficient across columns starting with prefix for each row in df.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame.\n",
    "        prefix: string prefix for target columns.\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with Gini coefficients per row.\n",
    "    \"\"\"\n",
    "    # Select columns matching the prefix\n",
    "    cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "    if not cols:\n",
    "        raise ValueError(f\"No columns found starting with prefix '{prefix}'\")\n",
    "\n",
    "    # Apply gini_coefficient row-wise across selected columns\n",
    "    gini_series = df[cols].apply(lambda row: gini_coefficient(row.values), axis=1)\n",
    "    return gini_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7ad29",
   "metadata": {},
   "source": [
    "#### Ressource depletion : to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae9678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0dc967",
   "metadata": {},
   "source": [
    "# Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing of filenames to get the parameters' values tested\n",
    "data_folder_name_acces = \"\"\n",
    "files_values = parse_results_filenames(data_folder_name_acces)\n",
    "\n",
    "# agregation of 2D Grid data\n",
    "df_maze_summary = aggregate_results_by_suffix(data_folder_name_acces, \"episode_summary\", source_filter=\"maze2d\")\n",
    "df_maze_step = aggregate_results_by_suffix(data_folder_name_acces, \"step_data\", source_filter=\"maze2d\")\n",
    "\n",
    "# Only aggregate GameTheoretic step data\n",
    "df_gt_summary = aggregate_results_by_suffix(data_folder_name_acces, \"step_data\", source_filter=\"Gametheoretic\")\n",
    "df_gt_step = aggregate_results_by_suffix(data_folder_name_acces, \"step_data\", source_filter=\"Gametheoretic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aea3e3",
   "metadata": {},
   "source": [
    "## Calculation of Dependent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98825e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the gini coef over personnal rewards\n",
    "df_maze_summary[\"gini_personal_reward\"] = compute_gini_for_df(df_maze_summary, prefix=\"total_personal_reward_\")\n",
    "df_maze_step[\"gini_personal_reward\"] = compute_gini_for_df(df_maze_step, prefix=\"total_personal_reward_\")\n",
    "\n",
    "df_gt_summary[\"gini_personal_reward\"] = compute_gini_for_df(df_gt_summary, prefix=\"personal_\")\n",
    "df_gt_step[\"gini_personal_reward\"] = compute_gini_for_df(df_gt_step, prefix=\"personal_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347ba7a",
   "metadata": {},
   "source": [
    "## Learning verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_maze_summary # summary csv to test for learning\n",
    "\n",
    "windowed_df = windowed_avg_combined_reward(\n",
    "    df=df,                                # summary dataframe to calculate upon\n",
    "    reward_prefix=\"total_combined_reward_\",  # or \"personal_\"\n",
    "    episode_column=\"episode\",             # the name of your episode column\n",
    "    simulation_id_column=\"simulation_index\",  # the name of your simulation ID column\n",
    "    window_size=10,                       # adjust smoothing window size\n",
    "    aggregation_mode=\"mean\",              # \"mean\" for average agent, \"best\" for best agent\n",
    "    plot=True                             # show plot of the result\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53efc1c",
   "metadata": {},
   "source": [
    "## Data Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e463fc1",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbdfed",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
