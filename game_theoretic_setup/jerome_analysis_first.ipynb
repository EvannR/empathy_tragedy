{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f5d9d8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2f8ffec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda237a",
   "metadata": {},
   "source": [
    "# General variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3f962",
   "metadata": {},
   "source": [
    " ## Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d883acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pattern of filenames\n",
    "\n",
    "GameTheoretic_filename_pattern_DQN =  re.compile(r\"results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_DQN_\"\n",
    "                                                r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "                                                r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[^_]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "                                                r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "                                                r\"(?P<batch_size>[\\d.]+)_(?P<hidden_size>[\\d.]+)_(?P<update_target_every>[\\d.]+)_\"\n",
    "                                                r\"(?P<random_suffix>\\d{6})_(?P<suffix>[a-zA-Z]+_[a-zA-Z]+)\\.csv\"\n",
    ")\n",
    "\n",
    "GameTheoretic_filename_pattern_QL = re.compile(r\"results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_QLearning_\"\n",
    "                                              r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "                                              r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[^_]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "                                              r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "                                              r\"(?P<random_suffix>\\d{6})_(?P<suffix>[a-zA-Z]+_[a-zA-Z]+)\\.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "Maze2D_filename_order_QL = re.compile(\n",
    "    r\"maze2d_results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_QLearning_\"\n",
    "    r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "    r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[^_]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "    r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "    r\"(?P<random_suffix>\\d{6})_(?P<suffix>[a-zA-Z]+_[a-zA-Z]+)\\.csv\"\n",
    ")\n",
    "\n",
    "Maze2D_filename_order_DQN = re.compile(\n",
    "    r\"maze2d_results_(?P<simulation_index>\\d{3})_(?P<episodes>\\d+)_DQN_\"\n",
    "    r\"(?P<emotion>[^_]+)_(?P<see_emotions>[^_]+)_\"\n",
    "    r\"(?P<alpha>[\\d.]+)_(?P<beta>[\\d.]+)_(?P<smoothing>[^_]+)_(?P<threshold>[\\d.]+)_(?P<rounder>[\\d.]+)_\"\n",
    "    r\"(?P<learning_rate>[\\d.]+)_(?P<gamma>[\\d.]+)_(?P<epsilon>[\\d.]+)_(?P<epsilon_decay>[\\d.]+)_(?P<epsilon_min>[\\d.]+)_\"\n",
    "    r\"(?P<batch_size>[\\d.]+)_(?P<hidden_size>[\\d.]+)_(?P<update_target_every>[\\d.]+)_\"\n",
    "    r\"(?P<random_suffix>\\d{6})_(?P<suffix>[a-zA-Z]+_[a-zA-Z]+)\\.csv\"\n",
    ")\n",
    "\n",
    "FILENAME_PATTERNS = [\n",
    "    GameTheoretic_filename_pattern_DQN,\n",
    "    GameTheoretic_filename_pattern_QL,\n",
    "    Maze2D_filename_order_DQN,\n",
    "    Maze2D_filename_order_QL\n",
    "]\n",
    "\n",
    "FILENAME_PATTERNS_PAIR = [\n",
    "    (\"Gametheoretic\", GameTheoretic_filename_pattern_DQN),\n",
    "    (\"Gametheoretic\", GameTheoretic_filename_pattern_QL),\n",
    "    (\"maze2d\", Maze2D_filename_order_DQN),\n",
    "    (\"maze2d\", Maze2D_filename_order_QL)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810fa323",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4083a",
   "metadata": {},
   "source": [
    "## CSV processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad5067",
   "metadata": {},
   "source": [
    "### Parameter recovery from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2748031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def parse_results_filenames(folder_path: str, filename_patterns=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scans a folder for result filenames and extracts simulation parameters into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing result CSV files.\n",
    "        filename_patterns (list): List of compiled regex patterns to match filenames.\n",
    "                                  If None, use global FILENAME_PATTERNS.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing parsed parameters from filenames.\n",
    "    \"\"\"\n",
    "    if filename_patterns is None:\n",
    "        filename_patterns = FILENAME_PATTERNS\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        matched = False\n",
    "        for pattern in filename_patterns:\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                file_data = match.groupdict()\n",
    "                file_data[\"filename\"] = filename\n",
    "                data.append(file_data)\n",
    "                matched = True\n",
    "                break  # Stop at the first match\n",
    "        \n",
    "        if not matched:\n",
    "            print(f\"Warning: filename did not match any pattern: {filename}\")\n",
    "\n",
    "    if not data:\n",
    "        print(\"No matching filenames found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Optional: convert numeric fields from str to float/int\n",
    "    for col in df.columns:\n",
    "        if col not in {\"filename\", \"emotion\", \"see_emotions\", \"suffix\"}:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "            except Exception:\n",
    "                pass  # leave as string if conversion fails\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d5b8ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_parameter_values(df: pd.DataFrame, exclude: list = None):\n",
    "    \"\"\"\n",
    "    Print a table with parameter names and their unique values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with simulation parameters.\n",
    "        exclude (list): Optional list of column names to exclude (e.g., ['filename', 'simulation_index']).\n",
    "    \"\"\"\n",
    "    if exclude is None:\n",
    "        exclude = ['filename', 'simulation_index']\n",
    "\n",
    "    param_cols = [col for col in df.columns if col not in exclude]\n",
    "\n",
    "    summary = {\n",
    "        \"parameter\": [],\n",
    "        \"unique_values\": []\n",
    "    }\n",
    "\n",
    "    for col in param_cols:\n",
    "        summary[\"parameter\"].append(col)\n",
    "        summary[\"unique_values\"].append(sorted(df[col].dropna().unique().tolist()))\n",
    "\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd5844",
   "metadata": {},
   "source": [
    "### Aggregation of csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ffa3efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results_by_suffix(folder_path: str, target_suffix: str, source_filter: str = None) -> pd.DataFrame:\n",
    "    all_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        for source_type, pattern in FILENAME_PATTERNS_PAIR:\n",
    "            if source_filter and source_type.lower() != source_filter.lower():\n",
    "                continue\n",
    "\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                metadata = match.groupdict()\n",
    "                if metadata.get(\"suffix\", \"\").strip() == target_suffix.strip():\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path)\n",
    "                        for key, value in metadata.items():\n",
    "                            df[key] = value\n",
    "                        df[\"source\"] = source_type.lower()  # normalize\n",
    "                        all_data.append(df)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {filename}: {e}\")\n",
    "                break\n",
    "\n",
    "    if not all_data:\n",
    "        print(f\"No matching files found for suffix '{target_suffix}' and source '{source_filter}'.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    for col in final_df.columns:\n",
    "        if col not in {\"emotion\", \"see_emotions\", \"suffix\", \"filename\", \"source\"}:\n",
    "            try:\n",
    "                final_df[col] = pd.to_numeric(final_df[col])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    filtered_tag = f\"_{source_filter.lower()}\" if source_filter else \"\"\n",
    "    output_filename = f\"aggregated_{target_suffix}{filtered_tag}.csv\"\n",
    "    output_path = os.path.join(folder_path, output_filename)\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved aggregated data to: {output_path}\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16bd09d",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b159a",
   "metadata": {},
   "source": [
    " ### Learning verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "89ec1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def windowed_avg_combined_reward(\n",
    "    df: pd.DataFrame,\n",
    "    reward_prefix: str = \"total_combined_reward_\",\n",
    "    episode_column: str = \"episode\",\n",
    "    simulation_id_column: str = \"simulation_index\",\n",
    "    window_size: int = 5,\n",
    "    aggregation_mode: str = \"mean\",  # or \"best\"\n",
    "    plot: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes a windowed moving average of combined rewards per episode across simulations.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        reward_prefix (str): Prefix of reward columns per agent.\n",
    "        episode_column (str): Column name for episodes.\n",
    "        simulation_id_column (str): Column indicating different simulations.\n",
    "        window_size (int): Window size for moving average.\n",
    "        aggregation_mode (str): 'mean' for average across agents, 'best' for max reward among agents.\n",
    "        plot (bool): Whether to plot the result.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with ['episode', 'aggregated_reward', 'moving_avg'].\n",
    "    \"\"\"\n",
    "    reward_cols = [col for col in df.columns if col.startswith(reward_prefix)]\n",
    "    if not reward_cols:\n",
    "        raise ValueError(f\"No columns found with prefix '{reward_prefix}'\")\n",
    "\n",
    "    if aggregation_mode == \"mean\":\n",
    "        df[\"aggregated_reward\"] = df[reward_cols].mean(axis=1)\n",
    "    elif aggregation_mode == \"best\":\n",
    "        df[\"aggregated_reward\"] = df[reward_cols].max(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"aggregation_mode must be 'mean' or 'best'\")\n",
    "\n",
    "    episode_avg = (\n",
    "        df.groupby(episode_column)[\"aggregated_reward\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"aggregated_reward\": \"mean_reward\"})\n",
    "    )\n",
    "\n",
    "    # Apply moving average\n",
    "    episode_avg[\"moving_avg\"] = (\n",
    "        episode_avg[\"mean_reward\"].rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(episode_avg[episode_column], episode_avg[\"moving_avg\"], label=f\"Moving Avg ({aggregation_mode})\")\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.title(f\"{aggregation_mode.capitalize()} Agent Reward (Window={window_size})\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return episode_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96180ba",
   "metadata": {},
   "source": [
    "### Variable_calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db0720",
   "metadata": {},
   "source": [
    "#### Gini coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "da6bcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coefficient(arr: np.ndarray) -> float:\n",
    "    \"\"\"Compute Gini coefficient of a 1D numpy array.\"\"\"\n",
    "    arr = arr.flatten()\n",
    "    if np.amin(arr) < 0:\n",
    "        arr = arr - np.amin(arr)  # Shift if negative values present\n",
    "    mean = np.mean(arr)\n",
    "    if mean == 0:\n",
    "        return 0.0\n",
    "    n = len(arr)\n",
    "    diff_sum = np.sum(np.abs(np.subtract.outer(arr, arr)))\n",
    "    gini = diff_sum / (2 * n**2 * mean)\n",
    "    return gini\n",
    "\n",
    "def compute_gini_for_df(df: pd.DataFrame, prefix: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute Gini coefficient across columns starting with prefix for each row in df.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame.\n",
    "        prefix: string prefix for target columns.\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with Gini coefficients per row.\n",
    "    \"\"\"\n",
    "    cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "    if not cols:\n",
    "        raise ValueError(f\"No columns found starting with prefix '{prefix}'\")\n",
    "\n",
    "    gini_series = df[cols].apply(lambda row: gini_coefficient(row.values), axis=1)\n",
    "    return gini_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a73761",
   "metadata": {},
   "source": [
    "#### Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d9c00a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_efficiency_for_df(df: pd.DataFrame, prefix: str, new_column_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the average across columns starting with a given prefix for each row in df.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        prefix (str): Prefix for selecting target columns.\n",
    "        new_column_name (str): Name of the new column to store the computed sum.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new column added.\n",
    "    \"\"\"\n",
    "    cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "    if not cols:\n",
    "        raise ValueError(f\"No columns found starting with prefix '{prefix}'\")\n",
    "\n",
    "    df[new_column_name] = df[cols].mean(axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7ad29",
   "metadata": {},
   "source": [
    "#### efficiency of agents : to discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7eae9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _clean_initial_resources_column(df: pd.DataFrame, col_name: str) -> None: # Added because sometimes they were str rather than int\n",
    "    \"\"\"Convert list-like string in initial_resources column to numeric.\"\"\"\n",
    "    def extract_number(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            if isinstance(parsed, (list, tuple)) and len(parsed) > 0:\n",
    "                return float(parsed[0])\n",
    "            else:\n",
    "                return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    if col_name in df.columns and df[col_name].dtype == object:\n",
    "        df[col_name] = df[col_name].apply(extract_number)\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors='coerce')\n",
    "\n",
    "def GT_compute_and_merge_depletion_from_step(df: pd.DataFrame) -> None:\n",
    "    _clean_initial_resources_column(df, 'initial_resources')\n",
    "\n",
    "    group_cols = ['simulation_index', 'episode']\n",
    "    grouped = df.groupby(group_cols)\n",
    "\n",
    "    depletion_metrics = grouped.agg(\n",
    "        final_resource=('resource_remaining', 'last'),\n",
    "        avg_resource=('resource_remaining', 'mean'),\n",
    "        initial_resource=('initial_resources', 'first')\n",
    "    ).reset_index()\n",
    "\n",
    "    depletion_metrics['depletion_final'] = 1 - depletion_metrics['final_resource'] / depletion_metrics['initial_resource']\n",
    "    depletion_metrics['depletion_cumulative'] = 1 - depletion_metrics['avg_resource'] / depletion_metrics['initial_resource']\n",
    "\n",
    "    merged = df.merge(\n",
    "        depletion_metrics[group_cols + ['depletion_final', 'depletion_cumulative']],\n",
    "        on=group_cols, how='left'\n",
    "    )\n",
    "\n",
    "    df.loc[:, 'depletion_final'] = merged['depletion_final']\n",
    "    df.loc[:, 'depletion_cumulative'] = merged['depletion_cumulative']\n",
    "\n",
    "\n",
    "def GT_compute_depletion_from_summary(df: pd.DataFrame) -> None:\n",
    "    # Clean initial_resources column if needed\n",
    "    _clean_initial_resources_column(df, 'initial_resources')\n",
    "\n",
    "    df.loc[:, 'depletion_final'] = 1 - df['resource_remaining'] / df['initial_resources']\n",
    "    df.loc[:, 'depletion_early'] = 1 - df['total_steps'] / df['max_steps']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e56d8",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0277a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fluctuation of a value over episodes or steps\n",
    "def plot_value_fluctuation_by_simulation(\n",
    "    df: pd.DataFrame,\n",
    "    value_col: str, # name of the column over which we study the fluctuation\n",
    "    simulation_col: str = 'seed',\n",
    "    episode_col: str = 'episode',\n",
    "    step_col: str = 'step',\n",
    "    is_step_csv: bool = False,\n",
    "    title: str = None,\n",
    "    ylabel: str = None,\n",
    "    rolling_window: int = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the fluctuation of a value averaged per simulation over episodes (summary) or (step, episode) (step CSV).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame (step or summary).\n",
    "        value_col (str): The column to track (e.g. 'resource_remaining', 'reward').\n",
    "        simulation_col (str): Column identifying the simulation (default 'seed').\n",
    "        episode_col (str): Column identifying the episode (default 'episode').\n",
    "        step_col (str): Column identifying the step (default 'step').\n",
    "        is_step_csv (bool): True if using step CSV; False if using summary CSV.\n",
    "        title (str): Optional plot title.\n",
    "        ylabel (str): Label for y-axis (default = value_col).\n",
    "        rolling_window (int): Optional window for smoothing (rolling mean).\n",
    "    \"\"\"\n",
    "    if is_step_csv:\n",
    "        group_cols = [simulation_col, episode_col, step_col]\n",
    "    else:\n",
    "        group_cols = [simulation_col, episode_col]\n",
    "\n",
    "    grouped = df.groupby(group_cols)[value_col].mean().reset_index()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for sim_id, sim_df in grouped.groupby(simulation_col):\n",
    "        x = sim_df[episode_col] if not is_step_csv else sim_df.groupby([episode_col])[step_col].apply(list)\n",
    "        y = sim_df[value_col]\n",
    "\n",
    "        if rolling_window:\n",
    "            y = y.rolling(rolling_window, min_periods=1).mean()\n",
    "\n",
    "        label = f\"Sim {sim_id}\"\n",
    "        plt.plot(sim_df[episode_col] if not is_step_csv else range(len(y)), y, label=label)\n",
    "\n",
    "    plt.xlabel('Episode' if not is_step_csv else 'Time (by episode/step)')\n",
    "    plt.ylabel(ylabel if ylabel else value_col)\n",
    "    plt.title(title or f\"Fluctuation of {value_col} over time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "86be37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# density function of the depletion per episode\n",
    "def plot_depletion_density_across_simulations(\n",
    "    df: pd.DataFrame,\n",
    "    depletion_col: str = 'depletion_final',\n",
    "    episode_col: str = 'episode',\n",
    "    method: str = 'kde',  # 'kde' or 'hist'\n",
    "    bandwidth: float = 0.3,\n",
    "    bins: int = 30,\n",
    "    title: str = \"efficiency of agents Density Across Simulations\",\n",
    "    figsize: tuple = (12, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a 2D density or histogram of depletion values across all simulations over episodes.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing at least 'episode' and 'depletion_final'.\n",
    "        depletion_col (str): Column for efficiency of agents.\n",
    "        episode_col (str): Column for episode index.\n",
    "        method (str): 'kde' for smoothed density, 'hist' for 2D histogram.\n",
    "        bandwidth (float): Smoothing parameter for KDE (ignored for hist).\n",
    "        bins (int): Number of bins for histogram (ignored for KDE).\n",
    "        title (str): Plot title.\n",
    "        figsize (tuple): Size of the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if method == 'kde':\n",
    "        sns.kdeplot(\n",
    "            data=df,\n",
    "            x=episode_col,\n",
    "            y=depletion_col,\n",
    "            fill=True,\n",
    "            cmap=\"mako\",\n",
    "            bw_adjust=bandwidth,\n",
    "            levels=100,\n",
    "            thresh=0.05\n",
    "        )\n",
    "    elif method == 'hist':\n",
    "        sns.histplot(\n",
    "            data=df,\n",
    "            x=episode_col,\n",
    "            y=depletion_col,\n",
    "            bins=bins,\n",
    "            pmax=0.95,\n",
    "            cbar=True,\n",
    "            cmap=\"mako\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'kde' or 'hist'\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Episode Number\")\n",
    "    plt.ylabel(\"efficiency of agents\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0dc967",
   "metadata": {},
   "source": [
    "# Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "59966418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: filename did not match any pattern: aggregated_episode_summary_gametheoretic.csv\n",
      "Warning: filename did not match any pattern: aggregated_step_data_gametheoretic.csv\n",
      "emotion see_emotions  alpha  beta smoothing  threshold  learning_rate  gamma  epsilon  epsilon_decay  epsilon_min  batch_size  hidden_size  update_target_every\n",
      "average         True    0.5   0.5    linear        0.5          0.001   0.99      1.0          0.995         0.01          16           64                    5\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Gather metadata from filenames ---\n",
    "folder_path = \".\"  # Folder containing the CSV results\n",
    "\n",
    "parameter_dataframe = parse_results_filenames(folder_path=folder_path)\n",
    "\n",
    "# Define the specific RL parameters of interest\n",
    "desired_params = [\n",
    "    \"emotion\", \"see_emotions\", \"alpha\", \"beta\", \"smoothing\", \"threshold\",\n",
    "    \"learning_rate\", \"gamma\", \"epsilon\", \"epsilon_decay\", \"epsilon_min\",\n",
    "    \"batch_size\", \"hidden_size\", \"update_target_every\"\n",
    "]\n",
    "\n",
    "param_cols = [col for col in parameter_dataframe.columns if col in desired_params]\n",
    "unique_values_per_param = {col: sorted(parameter_dataframe[col].unique()) for col in param_cols}\n",
    "\n",
    "# Convert to DataFrame with param names as columns and unique set of values as rows\n",
    "max_len = max(len(v) for v in unique_values_per_param.values())\n",
    "for k in unique_values_per_param:\n",
    "    unique_values_per_param[k] += [None] * (max_len - len(unique_values_per_param[k]))\n",
    "\n",
    "# Display of the unique sets of parameter values\n",
    "summary_df = pd.DataFrame(unique_values_per_param)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "24ed8d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching files found for suffix 'episode_summary' and source 'maze2d'.\n",
      "No matching files found for suffix 'step_data' and source 'maze2d'.\n",
      "Saved aggregated data to: .\\aggregated_episode_summary_gametheoretic.csv\n",
      "Saved aggregated data to: .\\aggregated_step_data_gametheoretic.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Aggregate data for Maze2D ---\n",
    "df_maze_summary = aggregate_results_by_suffix(\n",
    "    folder_path=folder_path,\n",
    "    target_suffix=\"episode_summary\",\n",
    "    source_filter=\"maze2d\"\n",
    ")\n",
    "\n",
    "df_maze_step = aggregate_results_by_suffix(\n",
    "    folder_path=folder_path,\n",
    "    target_suffix=\"step_data\",\n",
    "    source_filter=\"maze2d\"\n",
    ")\n",
    "\n",
    "# --- Aggregate data for GameTheoretic environment only ---\n",
    "df_gt_summary = aggregate_results_by_suffix(\n",
    "    folder_path=folder_path,\n",
    "    target_suffix=\"episode_summary\",\n",
    "    source_filter=\"Gametheoretic\"\n",
    ")\n",
    "\n",
    "df_gt_step = aggregate_results_by_suffix(\n",
    "    folder_path=folder_path,\n",
    "    target_suffix=\"step_data\",\n",
    "    source_filter=\"Gametheoretic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aea3e3",
   "metadata": {},
   "source": [
    "## Calculation of Dependent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6842deed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 32)\n",
      "(16357, 36)\n"
     ]
    }
   ],
   "source": [
    "print(df_gt_summary.shape)\n",
    "print(df_gt_step.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "98825e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Could not compute Gini for df_maze_summary: No columns found starting with prefix 'total_personal_reward_'\n",
      "[]\n",
      "Could not compute Gini for df_maze_step: No columns found starting with prefix 'personal_reward_'\n",
      "succesfull for GameTheoretic summary\n",
      "Could not compute Gini for df_gt_step: '<=' not supported between instances of 'float' and 'str'\n"
     ]
    }
   ],
   "source": [
    "# sets the name of the columns to compute the gini coefficient and utility over\n",
    "personal_column_gt_step_prefix = \"personal_reward_\"\n",
    "personal_column_gt_summary_prefix = \"total_personal_reward_\"\n",
    "personal_column_maze_step_prefix = \"personal_reward_\"\n",
    "personal_column_maze_summary_prefix = \"total_personal_reward_\"\n",
    "\n",
    "\n",
    "try:\n",
    "    print([col for col in df_maze_summary.columns if col.startswith(personal_column_maze_step_prefix)])\n",
    "    df_maze_summary[\"gini_personal_reward\"] = compute_gini_for_df(df_maze_summary, prefix=\"total_personal_reward_\")\n",
    "    print('succesfull for 2D summary')\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute Gini for df_maze_summary: {e}\")\n",
    "\n",
    "try:\n",
    "    print([col for col in df_maze_step.columns if col.startswith(personal_column_maze_step_prefix)])\n",
    "    df_maze_step[\"gini_personal_reward\"] = compute_gini_for_df(df_maze_step, prefix=personal_column_gt_step_prefix)\n",
    "    print('succesfull for 2D step')\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute Gini for df_maze_step: {e}\")\n",
    "\n",
    "try:\n",
    "    df_gt_summary[\"gini_personal_reward\"] = compute_gini_for_df(df_gt_summary, prefix=personal_column_gt_summary_prefix)\n",
    "    print('succesfull for GameTheoretic summary')\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute Gini for df_gt_summary: {e}\")\n",
    "\n",
    "try:\n",
    "    df_gt_step[\"gini_personal_reward\"] = compute_gini_for_df(df_gt_step, prefix=personal_column_gt_step_prefix)\n",
    "    print('succesfull for GameTheoretic step')\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute Gini for df_gt_step: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2e70a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully computed resource depletion from df_gt_step.\n",
      "Successfully computed resource depletion from df_gt_summary.\n",
      "Could not compute resource depletion from df_maze_step: 'simulation_index'\n",
      "Could not compute resource depletion from df_maze_summary: 'resource_remaining'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    GT_compute_and_merge_depletion_from_step(df_gt_step)  # creates \"depletion_final\" and \"depletion_cumulative\"\n",
    "    print(\"Successfully computed resource depletion from df_gt_step.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute resource depletion from df_gt_step: {e}\")\n",
    "\n",
    "try:\n",
    "    GT_compute_depletion_from_summary(df_gt_summary)  # creates \"depletion_cumulative\" and \"depletion_early\"\n",
    "    print(\"Successfully computed resource depletion from df_gt_summary.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute resource depletion from df_gt_summary: {e}\")\n",
    "\n",
    "# Will maybe need another formula for the 2D ?\n",
    "\n",
    "try:\n",
    "    GT_compute_and_merge_depletion_from_step(df_maze_step) \n",
    "    print(\"Successfully computed resource depletion from df_maze_step.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute resource depletion from df_maze_step: {e}\")\n",
    "\n",
    "try:\n",
    "    GT_compute_depletion_from_summary(df_maze_summary)\n",
    "    print(\"Successfully computed resource depletion from df_maze_summary.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute resource depletion from df_maze_summary: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "96d88da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not compute efficiency of agents from df_gt_step: unsupported operand type(s) for +: 'float' and 'str'\n",
      "Successfully computed efficiency of agents from df_gt_summary.\n",
      "Could not compute efficiency of agents from df_maze_step: No columns found starting with prefix 'personal_reward_'\n",
      "Could not compute efficiency of agents from df_maze_summary: No columns found starting with prefix 'total_personal_reward_'\n"
     ]
    }
   ],
   "source": [
    "# Compute the Efficiency of agents: set to the personal reward (dependent on resource consumption and not the social reward)\n",
    "prefix_step = personal_column_gt_step_prefix\n",
    "prefix_summary = personal_column_gt_summary_prefix\n",
    "\n",
    "try:\n",
    "    compute_efficiency_for_df(df=df_gt_step, prefix=prefix_step, new_column_name=f\"{prefix_step}_averaged_efficiency\")\n",
    "    print(\"Successfully computed efficiency of agents from df_gt_step.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute efficiency of agents from df_gt_step: {e}\")\n",
    "\n",
    "try:\n",
    "    compute_efficiency_for_df(df=df_gt_summary, prefix=prefix_summary, new_column_name=f\"{prefix_summary}_averaged_efficiency\")\n",
    "    print(\"Successfully computed efficiency of agents from df_gt_summary.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute efficiency of agents from df_gt_summary: {e}\")\n",
    "\n",
    "# Will maybe need another formula for the 2D?\n",
    "\n",
    "try:\n",
    "    compute_efficiency_for_df(df=df_maze_step, prefix=prefix_step, new_column_name=f\"{prefix_step}_averaged_efficiency\")\n",
    "    print(\"Successfully computed efficiency of agents from df_maze_step.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute efficiency of agents from df_maze_step: {e}\")\n",
    "\n",
    "try:\n",
    "    compute_efficiency_for_df(df=df_maze_summary, prefix=prefix_summary, new_column_name=f\"{prefix_summary}_averaged_efficiency\")\n",
    "    print(\"Successfully computed efficiency of agents from df_maze_summary.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute efficiency of agents from df_maze_summary: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347ba7a",
   "metadata": {},
   "source": [
    "## Learning verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "86ac3de0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'episodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[236], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m core_params \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m parameter_dataframe\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_suffix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffix\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 3. Group by unique experimental configurations\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_values, group \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(core_params):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Build readable label for logging\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(core_params, param_values))\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Processing Group: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jerome\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   9193\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Jerome\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1330\u001b[0m         obj,\n\u001b[0;32m   1331\u001b[0m         keys,\n\u001b[0;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1337\u001b[0m     )\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\Jerome\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'episodes'"
     ]
    }
   ],
   "source": [
    "df = df_gt_summary\n",
    "\n",
    "df = df.merge(parameter_dataframe, on=\"simulation_index\", how=\"left\")\n",
    "\n",
    "# 2. Define which parameters define a unique experiment setting\n",
    "core_params = [col for col in parameter_dataframe.columns if col not in ['filepath', 'random_suffix', 'suffix']]\n",
    "\n",
    "# 3. Group by unique experimental configurations\n",
    "for param_values, group in df.groupby(core_params):\n",
    "    # Build readable label for logging\n",
    "    label = ', '.join(f\"{k}={v}\" for k, v in zip(core_params, param_values))\n",
    "\n",
    "    print(f\"\\n--- Processing Group: {label} ---\")\n",
    "\n",
    "    # 4. Call your existing function for each group\n",
    "    windowed_df = windowed_avg_combined_reward(\n",
    "        df=group,\n",
    "        reward_prefix=\"total_combined_reward_\",\n",
    "        episode_column=\"episode\",\n",
    "        simulation_id_column=\"simulation_index\",\n",
    "        window_size=10,\n",
    "        aggregation_mode=\"mean\",\n",
    "        plot=True  # Or False if you're running in batch\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53efc1c",
   "metadata": {},
   "source": [
    "## Data Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fluctuation of ending ressources per episode\n",
    "plot_value_fluctuation_by_simulation(df_gt_summary, value_col='resource_remaining', is_step_csv=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac97253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot density function of the proportion of depletion\n",
    "plot_depletion_density_across_simulations(df_gt_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e463fc1",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats : t-test to compare the empathic comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbdfed",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
